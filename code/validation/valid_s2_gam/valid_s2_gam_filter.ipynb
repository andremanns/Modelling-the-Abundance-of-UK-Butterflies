{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83410339-8fe2-46ec-b143-78ea22f990d9",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "In order to maximise the number of records, baseline values have been predicted\n",
    "using either a stage 1 gam or an exponentially weighted mean (ewm). Now all survey groups \n",
    "with baseline indices (actual or predicted) need to be identified and grouped for the \n",
    "stage 2 gam analysis. All sites without a baseline must be removed from the dataset.\n",
    "\n",
    "#### Aim\n",
    "To aggregate all records with baseline indices in preperation for stage 2 GAM \n",
    "analysis. \n",
    "\n",
    "#### Workflow\n",
    "1) GAM predicted baseline dataframes are cleaned to make format consistent with ukbms dataframe\n",
    "2) ewm predicted baseline dataframes are cleaned to make format consistent with ukbms dataframe\n",
    "3) ukbms dataframe (actual survey data) is filtered by removing site/species \n",
    "combinations without an actual or predicted baseline.\n",
    "4) GAM and ewm predicted baselines are added to the main ukbms dataframe. \n",
    "5) log index ratios are computed for each record (these will be imputed into GAM stage \n",
    "2 models).\n",
    "6) A quality check is performed to ensure the number of records in the aggregated\n",
    "dataframe is correct.\n",
    "7) A final filter is performed, removing species groups with more than 15% zero \n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d6bf6c-f1ce-43d5-b485-ff58c651cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages and datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Importing localised file directory\n",
    "project_root = Path(os.environ['butterfly_project'])\n",
    "\n",
    "# Importing the main dataset (all study records)\n",
    "ukbms = pd.read_csv(project_root/'Data'/'UKBMS'/'ukbms_master_v1.csv', index_col=0)\n",
    "\n",
    "# Importing dataset with site/species combinations (merging consecutive survey groups).\n",
    "gam_prediction_records = pd.read_csv(project_root/'Data'/'UKBMS'/'gam_1'/'gam_1_accept.csv', index_col=0)\n",
    "\n",
    "# Importing GAM predictions\n",
    "gam_6_7_8 = pd.read_csv(project_root/'Data'/'UKBMS'/'gam_1'/'obs_6_7_8'/'obs_6_7_8_predictions.csv', index_col=0)\n",
    "gam_9_10_11 = pd.read_csv(project_root/'Data'/'UKBMS'/'gam_1'/'obs_9_10_11'/'obs_9_10_11_predictions.csv', index_col=0)\n",
    "gam_12_13_14 = pd.read_csv(project_root/'Data'/'UKBMS'/'gam_1'/'obs_12_13_14'/'obs_12_13_14_predictions.csv', index_col=0)\n",
    "gam_15_16_17 = pd.read_csv(project_root/'Data'/'UKBMS'/'gam_1'/'obs_15_16_17'/'obs_15_16_17_predictions.csv', index_col=0)\n",
    "gam_18_19_20 = pd.read_csv(project_root/'Data'/'UKBMS'/'gam_1'/'obs_18_19_20'/'obs_18_19_20_predictions.csv', index_col=0)\n",
    "\n",
    "# Importing ewm predictions\n",
    "ewm = pd.read_csv(project_root/'Data'/'UKBMS'/'ewm'/'ewm_predictions.csv', index_col=0)\n",
    "\n",
    "# Importing records which have no baseline and could not be predicted\n",
    "indices_rejected = pd.read_csv(project_root/'Data'/'UKBMS'/'ewm'/'ewm_reject.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b47c6c7a-155a-4121-a8ed-0aab64a09c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing redundant columns\n",
    "ukbms = ukbms.drop(columns=['country',\n",
    "                            'site_name',\n",
    "                            'gridreference',\n",
    "                            'easting',\n",
    "                            'northing',\n",
    "                            'species',\n",
    "                            'common_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc304e-e203-43ec-a9b1-7c63b662940c",
   "metadata": {},
   "source": [
    "#### Cleaning GAM Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bbaa1bf-a977-42d9-a1c7-9f7bc39570e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing GAM dataframes in a list\n",
    "gam_list = [gam_6_7_8, \n",
    "            gam_9_10_11, \n",
    "            gam_12_13_14, \n",
    "            gam_15_16_17, \n",
    "            gam_18_19_20]\n",
    "\n",
    "# Formatting of prediction dataframes needs to be tidied so they are compatible with \n",
    "# main 'ukbms' dataframe. \n",
    "for i in gam_list: # GAM dataframes are accessed by looping through 'gam_list'\n",
    "    i['year']=1993 # Adding a year column to all GAM dataframes\n",
    "    # Back-transforming log indices to count data. Count predictions were created \n",
    "    # using np.log1p(). To back-transform np.expm1() is used.\n",
    "    i['site_index'] = np.expm1(i['prediction_data'])\n",
    "\n",
    "# All GAM predictions are referenced by 'consecutive_survey_group'. To access the\n",
    "# the associated site and species codes, 'consecutive_survey_group' is used to merge\n",
    "# GAM dtaframes with 'gam_predictions_records'.  \n",
    "for i in np.arange(0,5,1): # Loops through items in 'gam_list'\n",
    "    gam_merge = (\n",
    "        gam_list[i]\n",
    "        .merge(gam_prediction_records[['site_code',\n",
    "                                       'species_code',\n",
    "                                       'consecutive_survey_group']],\n",
    "               on=['consecutive_survey_group'], # The primary key used to access codes\n",
    "               how='left')\n",
    "    )\n",
    "    # Columns in GAM dataframes are renamed for consistency with 'ukbms' df format\n",
    "    gam_merge = (\n",
    "        gam_merge\n",
    "        .rename(columns={'prediction_data':'log_site_index'})\n",
    "    )\n",
    "    # Cleaned dataframes are reassigned to 'gam_list'\n",
    "    gam_list[i] = (\n",
    "        gam_merge\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "        .drop(columns=['edof', 'consecutive_survey_group']) # Redundant columns removed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07936ee-bc4e-4b49-a3ef-8c00ee33bd26",
   "metadata": {},
   "source": [
    "#### Cleaning ewm Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbbdb489-92b8-40b5-a1f4-9f7a3e4e6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A year column is added to the ewm (exponentially weighted mean) predictions table. \n",
    "ewm['year'] = 1993\n",
    "\n",
    "# Redundant columns are removed. \n",
    "ewm = (\n",
    "    ewm\n",
    "    .rename(columns={'log_ewm':'log_site_index',\n",
    "                          'ewm':'site_index'})\n",
    "    .drop(columns=['record_count'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c187b-06c0-4306-a648-1fbdf2347986",
   "metadata": {},
   "source": [
    "#### Filtering the Main UKBMS DataFrame: Removing site/species Groups Without a Baseline Record\n",
    "\n",
    "Now the main dataframe 'ukbms' needs to be filtered to remove all records without a \n",
    "baseline. A filter is applied removing all site/species combinations without a survey \n",
    "between 1983 and 2003 (it was not possible to predict a baseline index for \n",
    "site/species combinations without a survey during this period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b14b36-c80a-420f-b02c-ed1a7e430280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbms_baseline_review = (\n",
    "    ukbms[(ukbms['year']>=1983) & (ukbms['year']<=2003)]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffbe83-a236-4566-a6fc-cf681e346331",
   "metadata": {},
   "source": [
    "See cell below:\n",
    "\n",
    "Removing site/species groups that were reviewed but failed to meet the GAM or ewm criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "348097f8-b95c-4216-9549-ffa05ef71160",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbms_indicator = (\n",
    "    ukbms_baseline_review\n",
    "    .merge(indices_rejected,\n",
    "           on=['site_code', 'species_code'],\n",
    "           how='left',\n",
    "           # 'indicator' creates a new column labelling rows that appear in left df only\n",
    "           indicator=True) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "372c3c3e-d714-46c9-9584-e4fc4c475d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indicator column ('_merge') is used for filtering. Only the records that appear \n",
    "# in the left dataframe are retained.\n",
    "ukbms_site_species_accepted = (\n",
    "    ukbms_indicator[ukbms_indicator['_merge']=='left_only'][['site_code',\n",
    "                                                             'species_code']]\n",
    "    .drop_duplicates() # Only unique site/species combinations are required. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c5b47-3cbf-4ad9-b890-765f38a46fc0",
   "metadata": {},
   "source": [
    "#### Adding a 'Buffer' Period for Improved GAM Boundary Stability\n",
    "The study period is 1993-2023, but to improve GAM boundary stability, records in the 5 years\n",
    "preceding the study period will be imputed into the model. 'ukbms_site_species_accepted' contains\n",
    "records of all accepted site/species combinations. It is used to access all the corresponding\n",
    "records from 'ukbms'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eca435c5-dc28-4e8f-bfeb-adc4570e0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbms_filtered = (\n",
    "    ukbms.merge(ukbms_site_species_accepted,\n",
    "                how='inner',\n",
    "                on=['site_code','species_code'])\n",
    ")\n",
    "\n",
    "# Keeping only years to be used for model input data\n",
    "ukbms_filtered = (\n",
    "    ukbms_filtered[ukbms_filtered['year']>=1988] \n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18d398-f34a-44cc-a203-73e8ce05d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting site indices to natural logs using np.log1p().\n",
    "# This ensures consistency with GAM and ewm dataframes\n",
    "ukbms_filtered['log_site_index'] = np.log1p(ukbms_filtered['site_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955738f6-d97c-4409-a27d-9b4ac871d654",
   "metadata": {},
   "source": [
    "#### Joining All Accepted Records: EWM Baseline Predictions, GAM baseline Predictions and All Remaining Records from 'ukbms_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d32dc0e-f0d0-4c5b-b329-69347136e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbms_combined = pd.concat([ukbms_filtered, # actual records\n",
    "                            ewm,\n",
    "                            gam_list[0], # GAM indices accessed by indexing 'gam_list'\n",
    "                            gam_list[1],\n",
    "                            gam_list[2],\n",
    "                            gam_list[3],\n",
    "                            gam_list[4]],\n",
    "                           ignore_index=True) # prevents duplicated df index labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed346b-6cb5-4311-a001-720afe8dabe8",
   "metadata": {},
   "source": [
    "#### Computing Log Index Ratios for Each Record\n",
    "All records in 'ukbms_combined' will be used in the analysis. Now the log index ratio can be \n",
    "calculated for each row. This is the main metric to be used in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "665de23c-3b46-4c16-8cc9-2188fe91df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First the baseline index is isolated \n",
    "baseline_indices = (\n",
    "    ukbms_combined[ukbms_combined['year']==1993][\n",
    "    ['site_code',\n",
    "     'species_code',\n",
    "     'log_site_index'] # the baseline index for each site/species combination\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Next, each site/species record is joined to its corresponding baseline.\n",
    "log_baseline = (\n",
    "    ukbms_combined.merge(baseline_indices,\n",
    "                         on=['site_code','species_code'],\n",
    "                         how='left',\n",
    "                         suffixes=['', '_baseline']) # to distinguish redundant columns\n",
    ")\n",
    "\n",
    "# 'log_site_index_baseline' column is isolated by subsetting the 'log_baseline' df and\n",
    "# assigned to a new variable: 'log_baseline_grouped'.\n",
    "log_baseline_grouped = (\n",
    "    log_baseline[['log_site_index_baseline']] \n",
    "    # The column name is modified to a more succinct heading\n",
    "    .rename(columns={'log_site_index_baseline':'log_baseline'})\n",
    ")\n",
    "\n",
    "# Single column dataframe (with log baselines indices) is copied over to main dataframe \n",
    "ukbms_combined['log_baseline'] = log_baseline_grouped\n",
    "\n",
    "# Computation of the log index ratio for each row\n",
    "# Index ratio in logs, is just a subraction\n",
    "ukbms_combined['log_index_ratio'] = (ukbms_combined['log_site_index'] \n",
    "                                     - ukbms_combined['log_baseline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f794f-6a99-4c89-b523-f1cb927bb1ae",
   "metadata": {},
   "source": [
    "#### Quality Check\n",
    "Checking to see if the aggregated total number of unique site/species baseline combinations \n",
    "in 'ukbms_combined' is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1fe537f-894f-4e50-9628-a85bb9c91605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique site/species combinations (1983-2003) TOTAL: 21027\n",
      "predicted baselines :5410\n",
      "actual baselines :7502\n",
      "baselines not predicted: 8115 \n",
      "\n",
      "ukbms_combined TOTAL: 12912\n"
     ]
    }
   ],
   "source": [
    "# The total number of unique records without a baseline between 1983 and 2023\n",
    "# An attempt to impute missing baselines was made for all site/species combinations \n",
    "# falling within this period.\n",
    "print(\n",
    "    'unique site/species combinations (1983-2003) TOTAL: ' \n",
    "    + str(\n",
    "        len(\n",
    "            # The evaluation period for site/species combinations without a baseline\n",
    "            ukbms[(ukbms['year']>=1983) & (ukbms['year']<=2003)] \n",
    "            .drop_duplicates(['site_code','species_code'])\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# The aggregated total number of predicted baseline indices\n",
    "print(\n",
    "    'predicted baselines :' \n",
    "    + str(\n",
    "        len(ewm) \n",
    "          + len(gam_list[0]) \n",
    "          + len(gam_list[1]) \n",
    "          + len(gam_list[2]) \n",
    "          + len(gam_list[3]) \n",
    "          + len(gam_list[4])\n",
    "    )\n",
    ")\n",
    "\n",
    "# Actual baseline values (The sites which were surveyed in 1993)\n",
    "print(\n",
    "    'actual baselines :' \n",
    "    + str(\n",
    "        len(ukbms[ukbms['year']==1993]\n",
    "              .drop_duplicates(['site_code','species_code']))\n",
    "    )\n",
    ")\n",
    "\n",
    "# The total number of baseline indices that could not be predicted\n",
    "print('baselines not predicted: ' + str(len(indices_rejected)), '\\n')\n",
    "\n",
    "# Checking to see if aggregated site/species baseline combinations matches original\n",
    "# number of records.\n",
    "print(\n",
    "    'ukbms_combined TOTAL: ' # unique site/species that will be used in the analysis\n",
    "    + str(\n",
    "        len(ukbms_combined[ukbms_combined['year']==1993])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038fbd25-3ce3-479d-b7c5-52ffc1fabdbc",
   "metadata": {},
   "source": [
    "#### Removing Species Groups with More than 15% Zero Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72261f16-a563-4504-969e-c14b3e4bae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbms_combined['proportion_zeroes'] = (\n",
    "    ukbms_combined\n",
    "    .groupby(['species_code'])['site_index']\n",
    "    # proportion of zeroes is computed as a decimal. \n",
    "    .transform(lambda x: sum(x==0)/len(x)) \n",
    ")\n",
    "\n",
    "# Filtering to only species groups that fall below zero threshold\n",
    "ukbms_zero_limit = ukbms_combined[ukbms_combined['proportion_zeroes']<=0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fd80cfa-54c8-4db3-8b15-65501e9a9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant column\n",
    "ukbms_species_analysis = (\n",
    "    ukbms_zero_limit\n",
    "    .drop(columns=['proportion_zeroes'])\n",
    "    .reset_index(drop=True) # Index is reset after zero filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e22cef16-03b4-4b37-9184-5777ebb1d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv file for records accepted for analysis. \n",
    "ukbms_species_analysis.to_csv(project_root/'Data'/'UKBMS'/'gam_2'/'ukbms_species_analysis.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo_env)",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
